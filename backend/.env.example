# Server Configuration
PORT=3000
NODE_ENV=development

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# LLM Parameters
LLM_TEMPERATURE=0.1
LLM_TOP_P=0.3
LLM_TOP_K=30
LLM_NUM_PREDICT=400
LLM_REPEAT_PENALTY=1.3

# ChromaDB Configuration (Mode Embedded - pas besoin de Docker)
# Les donnees seront stockees localement dans ./chromadb_data
CHROMADB_URL=./chromadb_data
CHROMADB_COLLECTION_NAME=email_knowledge_base

# RAG Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=300
TOP_K_RESULTS=6
RERANK_TOP_N=3

# Embedding Model
EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Logging
LOG_LEVEL=info
LOG_FILE=./logs/app.log

# CORS (pour ngrok)
ALLOWED_ORIGINS=https://*.ngrok-free.app,https://localhost:3000

# Knowledge Base Path
KNOWLEDGE_BASE_PATH=../docs
